import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.documents.base import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain_core.runnables import Runnable
from langchain.schema.output_parser import StrOutputParser
from langchain_community.document_loaders import PyMuPDFLoader
from typing import List, Tuple, Dict, Any, Optional  # [ë³€ê²½] ì¶”ê°€ íƒ€ì… ì„í¬íŠ¸
import os
import re
import csv
import time  # [ì¶”ê°€] time ëª¨ë“ˆ ì¶”ê°€
from dotenv import load_dotenv

# [ë³€ê²½] í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ê²€ì¦ ê°œì„ 
load_dotenv()
api_key = os.getenv("YOURKEY")
if not api_key:
    raise ValueError("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# [ë³€ê²½] ëª¨ë“ˆí™”: PDF ì²˜ë¦¬ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
class PDFProcessor:
    @staticmethod
    def pdf_to_documents(pdf_path: str) -> List[Document]:
        """PDF íŒŒì¼ì„ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            loader = PyMuPDFLoader(pdf_path)
            documents = loader.load()
            for d in documents:
                d.metadata['file_path'] = pdf_path
            return documents
        except Exception as e:  # [ì¶”ê°€] ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            st.error(f"PDF ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    @staticmethod
    def chunk_documents(documents: List[Document]) -> List[Document]:
        """Documentë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ë¶„í• """
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
        return text_splitter.split_documents(documents)

    @staticmethod
    def save_to_vector_store(documents: List[Document]) -> bool:  # [ë³€ê²½] ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ ë°˜í™˜
        """Documentë¥¼ ë²¡í„° DBì— ì €ì¥"""
        try:
            # [ë³€ê²½] API í‚¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=api_key)
            vector_store = FAISS.from_documents(documents, embedding=embeddings)
            vector_store.save_local("faiss_index")
            return True
        except Exception as e:  # [ì¶”ê°€] ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            st.error(f"ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

    @staticmethod
    def process_pdf(pdf_path: str) -> bool:  # [ì¶”ê°€] PDF ì²˜ë¦¬ë¥¼ í†µí•©í•˜ëŠ” ë©”ì„œë“œ ì¶”ê°€
        """PDF íŒŒì¼ ì²˜ë¦¬ ì‘ì—… í†µí•©"""
        if not os.path.exists(pdf_path):
            st.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
            return False
            
        documents = PDFProcessor.pdf_to_documents(pdf_path)
        if not documents:
            return False
            
        smaller_documents = PDFProcessor.chunk_documents(documents)
        return PDFProcessor.save_to_vector_store(smaller_documents)

# [ë³€ê²½] ëª¨ë“ˆí™”: RAG ì‹œìŠ¤í…œ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
class RAGSystem:
    def __init__(self, api_key: str):
        self.api_key = api_key
        
    def get_rag_chain(self) -> Runnable:
        """RAG ì²´ì¸ ìƒì„±"""
        template = """
        ì•„ë˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:
        - ì§ˆë¬¸ì— ëŒ€í•œ ì‘ë‹µì€ 5ì¤„ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        - ì• ë§¤í•˜ê±°ë‚˜ ëª¨ë¥´ëŠ” ë‚´ìš©ì€ "ì˜ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
        - ê³µì†í•œ í‘œí˜„ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

        ì»¨í…ìŠ¤íŠ¸: {context}

        ì§ˆë¬¸: {question}

        ì‘ë‹µ:"""

        custom_rag_prompt = PromptTemplate.from_template(template)
        # [ë³€ê²½] API í‚¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
        model = ChatOpenAI(model="gpt-4o", openai_api_key=self.api_key)

        return custom_rag_prompt | model | StrOutputParser()
    
    # [ë³€ê²½] ìºì‹± ë°ì½”ë ˆì´í„° ìˆ˜ì • (@st.cache_data ì œê±°, @st.cache_resourceë§Œ ì‚¬ìš©)
    @st.cache_resource
    def get_vector_db(self):
        """ë²¡í„° DB ë¡œë“œ"""
        try:
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", openai_api_key=self.api_key)
            return FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        except Exception as e:  # [ì¶”ê°€] ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            st.error(f"ë²¡í„° DB ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def process_question(self, user_question: str) -> Tuple[str, List[Document]]:  # [ë³€ê²½] ë°˜í™˜ íƒ€ì… ëª…ì‹œ
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ RAG ì²˜ë¦¬"""
        vector_db = self.get_vector_db()
        if not vector_db:  # [ì¶”ê°€] DB ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬
            return "ì‹œìŠ¤í…œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []
            
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        retriever = vector_db.as_retriever(search_kwargs={"k": 3})
        retrieve_docs = retriever.invoke(user_question)
        
        # RAG ì²´ì¸ í˜¸ì¶œ
        chain = self.get_rag_chain()
        
        try:
            response = chain.invoke({"question": user_question, "context": retrieve_docs})
            return response, retrieve_docs
        except Exception as e:  # [ì¶”ê°€] ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.", []

# [ì¶”ê°€] ëª¨ë“ˆí™”: UI ê´€ë ¨ ê¸°ëŠ¥ì„ í´ë˜ìŠ¤ë¡œ ë¶„ë¦¬
class ChatbotUI:
    @staticmethod
    def create_buttons(options):
        """ë²„íŠ¼ ìƒì„±"""
        for option in options:
            if isinstance(option, tuple):
                label, value = option
            else:
                label, value = option, option
                
            if st.button(label):
                st.session_state.selected_category = value
                return True  # [ë³€ê²½] ë²„íŠ¼ í´ë¦­ ì‹œ True ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •
        return False
                
    @staticmethod
    def natural_sort_key(s):
        """íŒŒì¼ëª… ìì—° ì •ë ¬ í‚¤ ìƒì„±"""
        return [int(text) if text.isdigit() else text for text in re.split(r'(\d+)', s)]
    
    @staticmethod
    def save_feedback(questions: List[Dict], feedbacks: List[Dict]) -> bool:  # [ë³€ê²½] ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€ ë°˜í™˜
        """ì‚¬ìš©ì ì§ˆë¬¸ ë° í”¼ë“œë°±ì„ CSVë¡œ ì €ì¥"""
        if not questions and not feedbacks:
            st.warning("ì €ì¥í•  ì§ˆë¬¸ ë˜ëŠ” í”¼ë“œë°± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
            
        try:
            # [ë³€ê²½] ì§ˆë¬¸ê³¼ í”¼ë“œë°± í˜•ì‹ í†µì¼ (ë”•ì…”ë„ˆë¦¬/ë¬¸ìì—´ ëª¨ë‘ ì²˜ë¦¬)
            formatted_questions = []
            for q in questions:
                if isinstance(q, dict) and "ì§ˆë¬¸" in q:
                    formatted_questions.append(q["ì§ˆë¬¸"])
                elif isinstance(q, str):
                    formatted_questions.append(q)
                    
            formatted_feedbacks = []
            for f in feedbacks:
                if isinstance(f, dict) and "í”¼ë“œë°±" in f:
                    formatted_feedbacks.append(f["í”¼ë“œë°±"])
                elif isinstance(f, str):
                    formatted_feedbacks.append(f)
            
            # ê¸¸ì´ ë§ì¶”ê¸°
            max_length = max(len(formatted_questions), len(formatted_feedbacks))
            formatted_questions.extend([""] * (max_length - len(formatted_questions)))
            formatted_feedbacks.extend([""] * (max_length - len(formatted_feedbacks)))
            
            # CSV ì €ì¥
            with open("questions_and_feedback.csv", mode="w", encoding="utf-8-sig", newline="") as file:
                writer = csv.writer(file)
                writer.writerow(["ì§ˆë¬¸", "í”¼ë“œë°±"])
                for q, f in zip(formatted_questions, formatted_feedbacks):
                    writer.writerow([q, f])
            return True
            
        except Exception as e:  # [ì¶”ê°€] ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            st.error(f"í”¼ë“œë°± ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False

def main():
    st.set_page_config(
        initial_sidebar_state="expanded",
        layout="wide",
        page_icon="ğŸ¤–",
        page_title="ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")

    # [ë³€ê²½] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”ë¥¼ í•œê³³ì—ì„œ ì²˜ë¦¬
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "selected_category" not in st.session_state:
        st.session_state.selected_category = None
    if "user_questions" not in st.session_state:
        st.session_state.user_questions = []
    if "user_feedback" not in st.session_state:
        st.session_state.user_feedback = []
    # [ì¶”ê°€] PDF ì²˜ë¦¬ ìƒíƒœ ì¶”ì ìš© ë³€ìˆ˜
    if "pdf_processed" not in st.session_state:
        st.session_state.pdf_processed = False

    # UI ì´ˆê¸°í™”
    st.header("ë””ì§€í„¸ê²½ì˜ì „ê³µ ì±—ë´‡")
    st.text("ì§ˆë¬¸í•˜ê³ ì‹¶ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")

    # [ì¶”ê°€] RAG ì‹œìŠ¤í…œ ë° UI í´ë˜ìŠ¤ ì´ˆê¸°í™”
    rag_system = RAGSystem(api_key)
    ui = ChatbotUI()

    # ë ˆì´ì•„ì›ƒ
    left1_column, left2_column, mid_column, right_column = st.columns([0.3, 0.3, 1, 0.9])
    
    # ì™¼ìª½ ì²« ë²ˆì§¸ ì—´ - ì¹´í…Œê³ ë¦¬
    with left1_column:
        st.text("ë””ì§€í„¸ê²½ì˜í•™ê³¼")
        
        categories = [
            "í•™ê³¼ ì •ë³´", "ì „ê³µ ê³¼ëª©", "êµë‚´ ì¥í•™ê¸ˆ", "í•™êµ í–‰ì‚¬",
            "ì†Œëª¨ì„", "ë¹„êµê³¼", "êµí™˜ í•™ìƒ"]

        # [ë³€ê²½] ë²„íŠ¼ í´ë¦­ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬ ê°œì„ 
        if ui.create_buttons(categories) and st.session_state.selected_category:
            # [ì¶”ê°€] ìŠ¤í”¼ë„ˆ ì¶”ê°€ë¡œ ì‚¬ìš©ìì—ê²Œ ì²˜ë¦¬ ì¤‘ì„ì„ ì•Œë¦¼
            with st.spinner(f"{st.session_state.selected_category} ì •ë³´ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                pdf_path = f"{st.session_state.selected_category}.pdf"
                st.session_state.pdf_processed = PDFProcessor.process_pdf(pdf_path)

    # ì™¼ìª½ ë‘ ë²ˆì§¸ ì—´ - í•™ë…„ë³„
    with left2_column:
        st.text("í•™ë…„ë³„")

        grade_levels = [
            ("20í•™ë²ˆ ì´ì „", "20ì´ì „"), ("21í•™ë²ˆ", "21"),
            ("22í•™ë²ˆ", "22"), ("23í•™ë²ˆ", "23"), ("24í•™ë²ˆ", "24")]

        # [ë³€ê²½] ë²„íŠ¼ í´ë¦­ ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬ ê°œì„ 
        if ui.create_buttons(grade_levels) and st.session_state.selected_category:
            # [ì¶”ê°€] ìŠ¤í”¼ë„ˆ ì¶”ê°€ë¡œ ì‚¬ìš©ìì—ê²Œ ì²˜ë¦¬ ì¤‘ì„ì„ ì•Œë¦¼
            with st.spinner(f"{st.session_state.selected_category} ì •ë³´ë¥¼ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤..."):
                pdf_path = f"{st.session_state.selected_category}.pdf"
                st.session_state.pdf_processed = PDFProcessor.process_pdf(pdf_path)

    # ì¤‘ì•™ ì—´ - ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    with mid_column:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì…ë ¥ ë° ì²˜ë¦¬
        prompt = st.chat_input("ì„ íƒí•˜ì‹  ì¹´í…Œê³ ë¦¬ì—ì„œ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")
        
        if prompt:
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # [ì¶”ê°€] ì¹´í…Œê³ ë¦¬ ì„ íƒ ì—¬ë¶€ í™•ì¸ ë¡œì§ ì¶”ê°€
            if not st.session_state.selected_category:
                with st.chat_message("assistant"):
                    assistant_response = "ë¨¼ì € ì™¼ìª½ì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
                    st.markdown(assistant_response)
                    st.session_state.messages.append({"role": "assistant", "content": assistant_response})
            # [ì¶”ê°€] PDF ì²˜ë¦¬ ìƒíƒœ í™•ì¸ ë¡œì§ ì¶”ê°€
            elif not st.session_state.pdf_processed:
                with st.chat_message("assistant"):
                    assistant_response = "ë°ì´í„° ì²˜ë¦¬ ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
                    st.markdown(assistant_response)
                    st.session_state.messages.append({"role": "assistant", "content": assistant_response})
            else:
                # ì§ˆë¬¸ ì²˜ë¦¬ ë° ì‘ë‹µ
                # [ì¶”ê°€] ìŠ¤í”¼ë„ˆ ì¶”ê°€ë¡œ ì‚¬ìš©ìì—ê²Œ ì²˜ë¦¬ ì¤‘ì„ì„ ì•Œë¦¼
                with st.spinner("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        response, context = rag_system.process_question(prompt)
                        with st.chat_message("assistant"):
                            st.markdown(response)
                            if context:
                                # [ê°œì„ ] ê´€ë ¨ ë¬¸ì„œ í‘œì‹œ ë°©ì‹ ê°œì„ 
                                with st.expander("ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
                                    for idx, document in enumerate(context, 1):
                                        st.subheader(f"ê´€ë ¨ ë¬¸ì„œ {idx}")
                                        st.write(document.page_content)
                        
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    except Exception as e:
                        st.error(f"ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # ì˜¤ë¥¸ìª½ ì—´ - í”¼ë“œë°± ë° ì¶”ê°€ ì§ˆë¬¸
    with right_column:
        # [ë³€ê²½] ì„¹ì…˜ ì œëª© ì¶”ê°€ë¡œ UI ëª…í™•ì„± í–¥ìƒ
        st.subheader("ì¶”ê°€ ì§ˆë¬¸ ë° í”¼ë“œë°±")
        
        # ì¶”ê°€ ì§ˆë¬¸ ì„¹ì…˜
        st.text("ì¶”ê°€ ì§ˆë¬¸")
        user_question = st.text_input(
            "ì±—ë´‡ì„ í†µí•´ ì •ë³´ë¥¼ ì–»ì§€ ëª»í•˜ì˜€ê±°ë‚˜ ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!",
            placeholder="ê³¼ëª© ë³€ê²½ or í–‰ì‚¬ ë¬¸ì˜"
        )

        # [ë³€ê²½] ë²„íŠ¼ì— key ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€
        if st.button("ì§ˆë¬¸ ì œì¶œ", key="submit_question"):
            if user_question:
                st.session_state.user_questions.append({"ì§ˆë¬¸": user_question})
                st.success("ì§ˆë¬¸ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                # [ì¶”ê°€] ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.experimental_rerun()
            else:
                st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

        # í”¼ë“œë°± ì„¹ì…˜
        st.text("")
        st.text("ì‘ë‹µ í”¼ë“œë°±")
        feedback = st.radio("ì‘ë‹µì´ ë§Œì¡±ìŠ¤ëŸ¬ìš°ì…¨ë‚˜ìš”?", ("ë§Œì¡±", "ë¶ˆë§Œì¡±"))

        if feedback == "ë§Œì¡±":
            st.success("ê°ì‚¬í•©ë‹ˆë‹¤! ë„ì›€ì´ ë˜ì–´ ê¸°ì©ë‹ˆë‹¤.")
        elif feedback == "ë¶ˆë§Œì¡±":
            st.warning("ë¶ˆë§Œì¡±í•˜ì‹  ë¶€ë¶„ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê² ìŠµë‹ˆë‹¤.")
            
            # ë¶ˆë§Œì¡± ì‚¬ìœ  ì…ë ¥
            reason = st.text_area("ë¶ˆë§Œì¡±í•œ ë¶€ë¶„ì´ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.")

            # [ë³€ê²½] ë²„íŠ¼ì— key ì¶”ê°€ë¡œ ì¤‘ë³µ ë°©ì§€
            if st.button("í”¼ë“œë°± ì œì¶œ", key="submit_feedback"):
                if reason:
                    st.session_state.user_feedback.append({"í”¼ë“œë°±": reason})
                    st.success("í”¼ë“œë°±ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    # [ì¶”ê°€] ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”ë¥¼ ìœ„í•œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                    st.experimental_rerun()
                else:
                    st.warning("ë¶ˆë§Œì¡± ì‚¬ìœ ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

        # ì§ˆë¬¸ ë° í”¼ë“œë°± CSV ì €ì¥
        st.text("")
        if st.button("ì§ˆë¬¸ ë° í”¼ë“œë°± ë“±ë¡í•˜ê¸°"):
            # [ë³€ê²½] ê°œì„ ëœ í”¼ë“œë°± ì €ì¥ í•¨ìˆ˜ ì‚¬ìš©
            if ui.save_feedback(st.session_state.user_questions, st.session_state.user_feedback):
                st.success("ì§ˆë¬¸ê³¼ í”¼ë“œë°±ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
                # [ì¶”ê°€] ë“±ë¡ í›„ ëª©ë¡ ì´ˆê¸°í™”
                st.session_state.user_questions = []
                st.session_state.user_feedback = []
                time.sleep(1)
                st.experimental_rerun()

        # ë¬¸ì˜ ì •ë³´
        st.text("")
        st.text("")
        # [ë³€ê²½] í…ìŠ¤íŠ¸ë¥¼ markdownìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ
        st.markdown("""
        ê³ ë ¤ëŒ€í•™êµ ì„¸ì¢…ìº í¼ìŠ¤ ë””ì§€í„¸ê²½ì˜ì „ê³µ í™ˆí˜ì´ì§€ë¥¼ ì°¸ê³ í•˜ê±°ë‚˜,
        ë””ì§€í„¸ê²½ì˜ì „ê³µ ì‚¬ë¬´ì‹¤(044-860-1560)ì— ì „í™”í•˜ì—¬ ë¬¸ì˜ì‚¬í•­ì„ ì ‘ìˆ˜í•˜ì„¸ìš”.
        """)

if __name__ == "__main__":
    main()

# start : streamlit run end.py
# stop : ctrl + c
